---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.


```{r}
# Load the necessary libraries
library(readr)
library(ggplot2)

# Load the CSV file
df <- read_csv("Tomatogirl_with_sentiment.csv")

# Convert the 'date' column to datetime format
df$date <- as.Date(df$date)

# Plot the sentiment over time with a linear regression line
ggplot(df, aes(x = date, y = sentiment)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Date", y = "Sentiment", title = "Sentiment Over Time") +
  theme_classic()

```


```{r}
ggplot(df, aes(x = sentiment)) +
  geom_histogram(bins = 10, alpha = 0.5, color = "black") +
  labs(x = "Sentiment", y = "Frequency", title = "Sentiment Distribution") +
  theme_classic()
```


```{r}
df$month <- format(df$date, "%Y-%m")
df$quarter <- format(df$date, "%Y-Q%q")
df$year <- format(df$date, "%Y")

ggplot(df, aes(x = month, y = sentiment)) +
  geom_boxplot() +
  labs(x = "Month", y = "Sentiment", title = "Sentiment by Month") +
  theme_classic()

ggplot(df, aes(x = quarter, y = sentiment)) +
  geom_boxplot() +
  labs(x = "Quarter", y = "Sentiment", title = "Sentiment by Quarter") +
  theme_classic()

ggplot(df, aes(x = year, y = sentiment)) +
  geom_boxplot() +
  labs(x = "Year", y = "Sentiment", title = "Sentiment by Year") +
  theme_classic()
```

```{r}
top_sentiment_days <- df[order(-df$sentiment), ]
bottom_sentiment_days <- df[order(df$sentiment), ]

print(top_sentiment_days[1:10, ])
print(bottom_sentiment_days[1:10, ])
```

```{r}
df$day_of_week <- format(df$date, "%A")

ggplot(df, aes(x = day_of_week, y = sentiment)) +
  geom_boxplot() +
  labs(x = "Day of the Week", y = "Sentiment", title = "Sentiment by Day of the Week") +
  theme_classic()
```

```{r}
# Create a line graph
ggplot(df, aes(x = date, y = sentiment)) +
  geom_line() +
  labs(x = "Date", y = "Sentiment", title = "Sentiment Over Time") +
  theme_classic()
```

```{r}

# Filter the data for 2023 and 2024
df_2023 <- df[df$date >= "2023-01-01" & df$date < "2024-01-01", ]
df_2024 <- df[df$date >= "2024-01-01", ]

# Plot the sentiment over time for 2023 and 2024
ggplot() +
  geom_point(data = df_2023, aes(x = date, y = sentiment, color = "2023")) +
  geom_smooth(data = df_2023, aes(x = date, y = sentiment, color = "2023"), method = "lm", se = FALSE) +
  geom_point(data = df_2024, aes(x = date, y = sentiment, color = "2024")) +
  geom_smooth(data = df_2024, aes(x = date, y = sentiment, color = "2024"), method = "lm", se = FALSE) +
  labs(x = "Date", y = "Sentiment", title = "Sentiment Over Time (2023 vs 2024)", color = "Year") +
  theme_classic()

```
```{r}
# Load the necessary libraries
library(readr)
library(ggplot2)
library(dplyr)

# Create a new column for the year
df$year <- format(df$date, "%Y")

# Calculate the rolling average
df <- df %>%
  arrange(date) %>%
  mutate(rolling_avg = (sentiment + lag(sentiment) + lag(sentiment, 2) + lag(sentiment, 3) + lag(sentiment, 4) + lag(sentiment, 5) + lag(sentiment, 6)) / 7)

# Plot the sentiment over time with a rolling average
ggplot(df, aes(x = date, y = sentiment)) +
  geom_point() +
  geom_line(aes(y = rolling_avg), color = "red") +
  labs(x = "Date", y = "Sentiment", title = "Sentiment Over Time (Rolling Average)") +
  theme_classic() +
  facet_wrap(~ year)


```


```{r}

# Plot the likes over time
ggplot(df, aes(x = date, y = likes)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Date", y = "Likes", title = "Likes Over Time") +
  theme_classic() +
  facet_wrap(~ year)

```

```{r}
# Load the necessary libraries
library(readr)
library(ggplot2)
library(dplyr)
library(wordcloud)
library(tidyverse)
library(RColorBrewer)

# Load the CSV file
df <- read_csv("Tomatogirl_with_sentiment.csv")

# Check if the file was loaded successfully
if (is.null(df)) {
  stop("Failed to load the CSV file")
}

# Convert the 'date' column to datetime format
df$date <- as.Date(df$date)

# Plot the sentiment over time with a linear regression line
ggplot(df, aes(x = date, y = sentiment)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Date", y = "Sentiment", title = "Sentiment Over Time") +
  theme_classic()

# Plot the sentiment distribution
ggplot(df, aes(x = sentiment)) +
  geom_histogram(bins = 10, alpha = 0.5, color = "black") +
  labs(x = "Sentiment", y = "Frequency", title = "Sentiment Distribution") +
  theme_classic()

# Create a new column for the month, quarter, and year
df$month <- format(df$date, "%Y-%m")
df$quarter <- format(df$date, "%Y-Q%q")
df$year <- format(df$date, "%Y")

# Plot the sentiment by month, quarter, and year
ggplot(df, aes(x = month, y = sentiment)) +
  geom_boxplot() +
  labs(x = "Month", y = "Sentiment", title = "Sentiment by Month") +
  theme_classic()

ggplot(df, aes(x = quarter, y = sentiment)) +
  geom_boxplot() +
  labs(x = "Quarter", y = "Sentiment", title = "Sentiment by Quarter") +
  theme_classic()

ggplot(df, aes(x = year, y = sentiment)) +
  geom_boxplot() +
  labs(x = "Year", y = "Sentiment", title = "Sentiment by Year") +
  theme_classic()

# Find the top and bottom sentiment days
top_sentiment_days <- df[order(-df$sentiment), ]
bottom_sentiment_days <- df[order(df$sentiment), ]

print(top_sentiment_days[1:10, ])
print(bottom_sentiment_days[1:10, ])

# Create a new column for the day of the week
df$day_of_week <- format(df$date, "%A")

# Plot the sentiment by day of the week
ggplot(df, aes(x = day_of_week, y = sentiment)) +
  geom_boxplot() +
  labs(x = "Day of the Week", y = "Sentiment", title = "Sentiment by Day of the Week") +
  theme_classic()

# Create a line graph
ggplot(df, aes(x = date, y = sentiment)) +
  geom_line() +
  labs(x = "Date", y = "Sentiment", title = "Sentiment Over Time") +
  theme_classic()

# Filter the data for 2023 and 2024
df_2023 <- df[df$date >= "2023-01-01" & df$date < "2024-01-01", ]
df_2024 <- df[df$date >= "2024-01-01", ]

# Plot the sentiment over time for 2023 and 2024
ggplot() +
  geom_point(data = df_2023, aes(x = date, y = sentiment, color = "2023")) +
  geom_smooth(data = df_2023, aes(x = date, y = sentiment, color = "2023"), method = "lm", se = FALSE) +
  geom_point(data = df_2024, aes(x = date, y = sentiment, color = "2024")) +
  geom_smooth(data = df_2024, aes(x = date, y = sentiment, color = "2024"), method = "lm", se = FALSE) +
  labs(x = "Date", y = "Sentiment", title = "Sentiment Over Time (2023 vs 2024)", color = "Year") +
  theme_classic()

# Calculate the rolling average
df <- df %>%
  arrange(date) %>%
  mutate(rolling_avg = (sentiment + lag(sentiment) + lag(sentiment, 2) + lag(sentiment, 3) + lag(sentiment, 4) + lag(sentiment, 5) + lag(sentiment, 6)) / 7)

# Plot the sentiment over time with a rolling average
ggplot(df, aes(x = date, y = sentiment)) +
  geom_point() +
  geom_line(aes(y = rolling_avg), color = "red") +
  labs(x = "Date", y = "Sentiment", title = "Sentiment Over Time (Rolling Average)") +
  theme_classic() +
  facet_wrap(~ year)

# Plot the likes over time
ggplot(df, aes(x = date, y = likes)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Date", y = "Likes", title = "Likes Over Time") +
  theme_classic() +
  facet_wrap(~ year)

# Calculate the IQR
q1 <- quantile(df$likes, 0.25)
q3 <- quantile(df$likes, 0.75)
iqr <- q3 - q1

# Remove outliers
df_adjusted <- df[df$likes > q1 - 1.5 * iqr & df$likes < q3 + 1.5 * iqr, ]

# Plot the likes over time
ggplot(df_adjusted, aes(x = date, y = likes)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Date", y = "Likes", title = "Likes Over Time, without outliers") +
  theme_classic() +
  facet_wrap(~ year)

# Plot the sentiment vs. likes
ggplot(df_adjusted, aes(x = sentiment, y = likes)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "Sentiment", y = "Likes", title = "Sentiment vs. Likes") +
  theme_classic()

# Plot the likes distribution
ggplot(df, aes(x = likes)) +
  geom_histogram(bins = 30, color = "black", fill = "lightblue") +
  labs(x = "Likes", y = "Frequency", title = "Likes Distribution") +
  theme_classic()

# Find the top 10 days with the most likes
top_10_days <- df %>%
  arrange(desc(likes)) %>%
  head(10)

ggplot(top_10_days, aes(x = date, y = likes)) +
  geom_col() +
  labs(x = "Date", y = "Likes", title = "Top 10 Days with Most Likes") +
  theme_classic()

# Plot the likes by year
ggplot(df, aes(x = year, y = likes)) +
  geom_boxplot() +
  labs(x = "Year", y = "Likes", title = "Likes by Year") +
  theme_classic()

# Create word clouds for 2023 and 2024
df_2023 <- df[df$date >= "2023-01-01" & df$date < "2024-01-01", ]
df_2024 <- df[df$date >= "2024-01-01", ]
pal <- brewer.pal(8, "Accent")

png("wordcloud_2023.png", width = 3000, height = 2400, res = 300)
wordcloud(words = df_2023$accumulated_text, 
          max.words = 200, 
          min.freq = 2,
          random.order = FALSE, 
          main = "2023 Word Cloud",
          colors=pal,
          scale = c(3, 0.3))
dev.off() 

wordcloud(words = df_2024$accumulated_text, 
          max.words = 200, 
          min.freq = 2,
          random.order = FALSE, 
          main = "2024 Word Cloud",
          colors=pal,
          scale = c(3, 0.3))


```


```{r}
# Load the necessary libraries
library(readr)
library(ggplot2)
library(dplyr)
library(wordcloud)
library(tidyverse)
library(RColorBrewer)

# Function to process each CSV file
process_core_sentiment <- function(file_path, core_name) {
  # Load the CSV file
  df <- read_csv(file_path)
  
  # Convert the 'date' column to datetime format
  df$date <- as.Date(df$date)
  
  # Create new columns for time-related features
  df$month <- format(df$date, "%Y-%m")
  df$quarter <- format(df$date, "%Y-Q%q")
  df$year <- format(df$date, "%Y")
  df$day_of_week <- format(df$date, "%A")
  
  # Directory to save images
  save_dir <- "core_sentiment_images"
  if (!dir.exists(save_dir)) {
    dir.create(save_dir)
  }
  
  # Save sentiment over time plot
  p1 <- ggplot(df, aes(x = date, y = sentiment)) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE) +
    labs(x = "Date", y = "Sentiment", title = paste0(core_name, ": Sentiment Over Time")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_sentiment_over_time.png"), plot = p1)
  
  # Save sentiment distribution plot
  p2 <- ggplot(df, aes(x = sentiment)) +
    geom_histogram(bins = 10, alpha = 0.5, color = "black") +
    labs(x = "Sentiment", y = "Frequency", title = paste0(core_name, ": Sentiment Distribution")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_sentiment_distribution.png"), plot = p2)
  
  # Save sentiment by month, quarter, and year
  p3_month <- ggplot(df, aes(x = month, y = sentiment)) +
    geom_boxplot() +
    labs(x = "Month", y = "Sentiment", title = paste0(core_name, ": Sentiment by Month")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_sentiment_by_month.png"), plot = p3_month)
  
  p3_quarter <- ggplot(df, aes(x = quarter, y = sentiment)) +
    geom_boxplot() +
    labs(x = "Quarter", y = "Sentiment", title = paste0(core_name, ": Sentiment by Quarter")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_sentiment_by_quarter.png"), plot = p3_quarter)
  
  p3_year <- ggplot(df, aes(x = year, y = sentiment)) +
    geom_boxplot() +
    labs(x = "Year", y = "Sentiment", title = paste0(core_name, ": Sentiment by Year")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_sentiment_by_year.png"), plot = p3_year)
  
  # Save top and bottom sentiment days
  top_sentiment_days <- df[order(-df$sentiment), ]
  bottom_sentiment_days <- df[order(df$sentiment), ]
  
  # Save sentiment by day of the week
  p4 <- ggplot(df, aes(x = day_of_week, y = sentiment)) +
    geom_boxplot() +
    labs(x = "Day of the Week", y = "Sentiment", title = paste0(core_name, ": Sentiment by Day of the Week")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_sentiment_by_day_of_week.png"), plot = p4)
  
  # Save line graph of sentiment over time
  p5 <- ggplot(df, aes(x = date, y = sentiment)) +
    geom_line() +
    labs(x = "Date", y = "Sentiment", title = paste0(core_name, ": Sentiment Over Time")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_sentiment_line_graph.png"), plot = p5)
  
  # Split data for 2023 and 2024
  df_2023 <- df[df$date >= "2023-01-01" & df$date < "2024-01-01", ]
  df_2024 <- df[df$date >= "2024-01-01", ]
  
  # Save sentiment over time for 2023 and 2024
  p6 <- ggplot() +
    geom_point(data = df_2023, aes(x = date, y = sentiment, color = "2023")) +
    geom_smooth(data = df_2023, aes(x = date, y = sentiment, color = "2023"), method = "lm", se = FALSE) +
    geom_point(data = df_2024, aes(x = date, y = sentiment, color = "2024")) +
    geom_smooth(data = df_2024, aes(x = date, y = sentiment, color = "2024"), method = "lm", se = FALSE) +
    labs(x = "Date", y = "Sentiment", title = paste0(core_name, ": Sentiment Over Time (2023 vs 2024)"), color = "Year") +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_sentiment_2023_vs_2024.png"), plot = p6)
  
  # Calculate rolling average
  df_rolling <- df %>%
    arrange(date) %>%
    mutate(rolling_avg = (sentiment + lag(sentiment) + lag(sentiment, 2) + lag(sentiment, 3) + lag(sentiment, 4) + lag(sentiment, 5) + lag(sentiment, 6)) / 7)
  
  # Save sentiment with rolling average
  p7 <- ggplot(df_rolling, aes(x = date, y = sentiment)) +
    geom_point() +
    geom_line(aes(y = rolling_avg), color = "red") +
    labs(x = "Date", y = "Sentiment", title = paste0(core_name, ": Sentiment Over Time (Rolling Average)")) +
    theme_classic() +
    facet_wrap(~ year)
  ggsave(paste0(save_dir, "/", core_name, "_sentiment_rolling_average.png"), plot = p7)
  
  # Save likes over time
  p8 <- ggplot(df, aes(x = date, y = likes)) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE) +
    labs(x = "Date", y = "Likes", title = paste0(core_name, ": Likes Over Time")) +
    theme_classic() +
    facet_wrap(~ year)
  ggsave(paste0(save_dir, "/", core_name, "_likes_over_time.png"), plot = p8)
  
  # Calculate IQR and remove outliers
  q1 <- quantile(df$likes, 0.25)
  q3 <- quantile(df$likes, 0.75)
  iqr <- q3 - q1
  df_adjusted <- df[df$likes > q1 - 1.5 * iqr & df$likes < q3 + 1.5 * iqr, ]
  
  # Save likes over time without outliers
  p9 <- ggplot(df_adjusted, aes(x = date, y = likes)) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE) +
    labs(x = "Date", y = "Likes", title = paste0(core_name, ": Likes Over Time, without outliers")) +
    theme_classic() +
    facet_wrap(~ year)
  ggsave(paste0(save_dir, "/", core_name, "_likes_over_time_without_outliers.png"), plot = p9)
  
  # Save sentiment vs. likes
  p10 <- ggplot(df_adjusted, aes(x = sentiment, y = likes)) +
    geom_point() +
    geom_smooth(method = "lm", se = FALSE) +
    labs(x = "Sentiment", y = "Likes", title = paste0(core_name, ": Sentiment vs. Likes")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_sentiment_vs_likes.png"), plot = p10)
  
  # Save likes distribution
  p11 <- ggplot(df, aes(x = likes)) +
    geom_histogram(bins = 30, color = "black", fill = "lightblue") +
    labs(x = "Likes", y = "Frequency", title = paste0(core_name, ": Likes Distribution")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_likes_distribution.png"), plot = p11)
  
  # Save top 10 days with most likes
  top_10_days <- df %>%
    arrange(desc(likes)) %>%
    head(10)
  
  p12 <- ggplot(top_10_days, aes(x = date, y = likes)) +
    geom_col() +
    labs(x = "Date", y = "Likes", title = paste0(core_name, ": Top 10 Days with Most Likes")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_top_10_days_most_likes.png"), plot = p12)
  
  # Save likes by year
  p13 <- ggplot(df, aes(x = year, y = likes)) +
    geom_boxplot() +
    labs(x = "Year", y = "Likes", title = paste0(core_name, ": Likes by Year")) +
    theme_classic()
  ggsave(paste0(save_dir, "/", core_name, "_likes_by_year.png"), plot = p13)
  
  # Create word clouds for 2023 and 2024
  pal <- brewer.pal(8, "Accent")
  
  df_2023_core <- df_2023
  df_2024_core <- df_2024
  
  # Save word cloud for 2023
  wordcloud(
    words = df_2023_core$accumulated_text,
    max.words = 100,
    min.freq = 2,
    random.order = FALSE,
    main = paste0(core_name, " 2023 Word Cloud"),
    colors = pal,
    scale = c(3, 0.3)
  )
  ggsave(paste0(save_dir, "/", core_name, "_2023_wordcloud.png"))
  
  # Save word cloud for 2024
  wordcloud(
    words = df_2024_core$accumulated_text,
    max.words = 100,
    min.freq = 2,
    random.order = FALSE,
    main = paste0(core_name, " 2024 Word Cloud"),
    colors = pal,
    scale = c(3, 0.3)
  )
  ggsave(paste0(save_dir, "/", core_name, "_2024_wordcloud.png"))
  
  # Remove temporary data
  rm(df, df_2023, df_2024, df_rolling, df_adjusted, top_10_days, df_2023_core, df_2024_core)
}

# List of core files to process
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Process each file
for (file in core_files) {
  file_path <- file
  core_name <- gsub("_with_sentiment.csv", "", file)
  process_core_sentiment(file_path, core_name)
}
```

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)

# List of core files to process
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Read all CSV files into a list of data frames
data_list <- lapply(core_files, read.csv)

# Extract core names from file names
core_names <- gsub("_with_sentiment.csv", "", core_files)

# Add core name to each dataframe in the list
data_list <- mapply(
  function(df, core_name) {
    df$core <- core_name
    df
  },
  data_list,
  core_names,
  SIMPLIFY = FALSE
)

# Combine the data frames into one
combined_data <- do.call(rbind, data_list)

# Convert the data to long format
long_data <- combined_data %>%
  pivot_longer(
    cols = c(likes, views, comments, shares, collects),
    names_to = "metric",
    values_to = "value"
  )

# Create the graph
ggplot(long_data, aes(x = date, y = value, color = metric)) +
  geom_line(size = 1) +
  geom_point() +
  labs(
    title = "Social Media Metrics Over Time",
    x = "Timeline",
    y = "Count",
    color = "Metric"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_brewer(palette = "Dark2")

# Save the graph
ggsave("social_media_metrics.png", width = 10, height = 6, dpi = 300)
```

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)

# List of core files to process
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Read all CSV files into a list of data frames
data_list <- lapply(core_files, read.csv)

# Extract core names from file names
core_names <- gsub("_with_sentiment.csv", "", core_files)

# Add core name to each dataframe in the list
data_list <- mapply(
  function(df, core_name) {
    df$core <- core_name
    df
  },
  data_list,
  core_names,
  SIMPLIFY = FALSE
)

# Combine the data frames into one
combined_data <- do.call(rbind, data_list)

# Convert the data to long format
long_data <- combined_data %>%
  pivot_longer(
    cols = c(likes, views, comments, shares, collects),
    names_to = "metric",
    values_to = "value"
  )

# Ensure the date column is in the correct format
long_data$date <- as.Date(long_data$date)

# Create separate graphs for each metric with trendlines
metrics <- c("likes", "views", "comments", "shares", "collects")

walk(metrics, function(metric) {
  metric_data <- long_data %>% 
    filter(.data$metric == !!metric)
  
  ggplot(metric_data, aes(x = date, y = value, color = core)) +
    geom_smooth(aes(color = core), 
                 method = "loess", 
                 method.args = list(span = 0.8), 
                 size = 1, 
                 se = FALSE) +
    geom_point(aes(x = date, y = value), 
               size = 0.5, 
               color = "grey", 
               alpha = 0.3) +
    labs(
      title = paste("Trend of", metric, "Over Time"),
      x = "Timeline",
      y = "Count",
      color = "Core"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "bottom") +
    scale_color_brewer(palette = "Dark2") +
    theme(legend.title = element_blank()) +
    theme(plot.title = element_text(hjust = 0.5))
  
  ggsave(paste0("trend_", metric, "_metrics.png"), 
         width = 10, 
         height = 6, 
         dpi = 300)
})
```

```{r}

# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)

# List of core files to process
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Read all CSV files into a list of data frames
data_list <- lapply(core_files, read.csv)

# Extract core names from file names
core_names <- gsub("_with_sentiment.csv", "", core_files)

# Add core name to each dataframe in the list
data_list <- mapply(
  function(df, core_name) {
    df$core <- core_name
    df
  },
  data_list,
  core_names,
  SIMPLIFY = FALSE
)

# Combine the data frames into one
combined_data <- do.call(rbind, data_list)

# Convert the data to long format
long_data <- combined_data %>%
  pivot_longer(
    cols = c(likes, views, comments, shares, collects),
    names_to = "metric",
    values_to = "value"
  )

# Ensure the date column is in the correct format
long_data$date <- as.Date(long_data$date)

# Function to remove outliers using IQR
remove_outliers <- function(data, metric) {
  q1 <- quantile(data$value, 0.25)
  q3 <- quantile(data$value, 0.75)
  iqr <- q3 - q1
  
  lower_bound <- q1 - 1.5 * iqr
  upper_bound <- q3 + 1.5 * iqr
  
  data %>% filter(value >= lower_bound, value <= upper_bound)
}

# Create separate graphs for each metric with trendlines
metrics <- c("likes", "views", "comments", "shares", "collects")

walk(metrics, function(metric) {
  metric_data <- long_data %>% 
    filter(metric == !!metric) %>% 
    group_by(core) %>% 
    do(remove_outliers(., !!metric))
  
  ggplot(metric_data, aes(x = date, y = value, color = core)) +
    geom_smooth(aes(color = core), 
                 method = "loess", 
                 method.args = list(span = 0.8), 
                 size = 1, 
                 se = FALSE) +
    geom_point(aes(x = date, y = value), 
               size = 0.5, 
               color = "grey", 
               alpha = 0.3) +
    labs(
      title = paste("Trend of", metric, "Over Time (Without Outliers)"),
      x = "Timeline",
      y = "Count",
      color = "Core"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          legend.position = "bottom") +
    scale_color_brewer(palette = "Dark2") +
    theme(legend.title = element_blank()) +
    theme(plot.title = element_text(hjust = 0.5))
  
  ggsave(paste0("trend_", metric, "_metrics_without_outliers.png"), 
         width = 10, 
         height = 6, 
         dpi = 300)
})
```


```{r}

# Load necessary libraries
library(ggplot2)
library(readr)
library(dplyr)

# Load the core files
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Create a list to store the data frames
df_list <- list()

# Load each file and add a core column
for (file in core_files) {
  core_name <- gsub("_with_sentiment.csv", "", file)
  df <- read_csv(file)
  df$core <- core_name
  df_list[[core_name]] <- df
}

# Bind the data frames together
df <- bind_rows(df_list)

# Create the plot
p <- ggplot(df, aes(x = views, y = likes, size = sentiment, color = core)) +
  geom_point(alpha = 0.2) +
  scale_size_continuous(name = "Sentiment") +
  scale_color_discrete(name = "Core") +
  labs(x = "Views", y = "Likes") +
  theme_classic()

# Save the plot
ggsave("core_plot.png", plot = p, width = 10, height = 8, dpi = 300)

# Display the plot
p




```

```{r}
# Load necessary libraries
library(ggplot2)
library(readr)
library(dplyr)

# Load the core files
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Create a list to store the data frames
df_list <- list()

# Load each file and add a core column
for (file in core_files) {
  core_name <- gsub("_with_sentiment.csv", "", file)
  df <- read_csv(file)
  df$core <- core_name
  df_list[[core_name]] <- df
}

# Bind the data frames together
df <- bind_rows(df_list)

# Create individual plots for each core
cores <- unique(df$core)
for (core in cores) {
  core_df <- df %>% filter(core == core)
  p <- ggplot(core_df, aes(x = views, y = likes, size = sentiment)) +
    geom_point(alpha = 0.5) +
    scale_size_continuous(name = "Sentiment") +
    labs(x = "Views", y = "Likes", title = paste0(core, " Core")) +
    theme_classic()
  
  # Save the plot
  ggsave(paste0(core, "_plot.png"), plot = p, width = 8, height = 6, dpi = 300)
  
  # Display the plot
  print(p)
}
```


```{r}
# Load necessary libraries
library(ggplot2)
library(readr)
library(dplyr)

# Load the core files
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Create a list to store the data frames
df_list <- list()

# Load each file and add a core column
for (file in core_files) {
  core_name <- gsub("_with_sentiment.csv", "", file)
  df <- read_csv(file)
  df$core <- core_name
  df_list[[core_name]] <- df
}

# Bind the data frames together
df <- bind_rows(df_list)

# Convert date column to Date format
df$date <- as.Date(df$date)

# Create individual plots for each core
cores <- unique(df$core)
for (core in cores) {
  core_df <- df %>% filter(core == core)
  
  # Create a plot for date vs views with sentiment as size
  p <- ggplot(core_df, aes(x = date, y = views, size = sentiment)) +
    geom_point(alpha = 0.5) +
    scale_size_continuous(name = "Sentiment") +
    labs(x = "Date", y = "Views", title = paste0(core, " Date vs Views")) +
    theme_classic()
  
  # Save the plot
  ggsave(paste0(core, "_date_vs_views.png"), plot = p, width = 8, height = 6, dpi = 300)
  
  # Display the plot
  print(p)
}
```

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)

# List of core files to process
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Read all CSV files into a list of data frames
data_list <- lapply(core_files, read.csv)

# Extract core names from file names
core_names <- gsub("_with_sentiment.csv", "", core_files)

# Add core name to each dataframe in the list
data_list <- mapply(
  function(df, core_name) {
    df$core <- core_name
    df
  },
  data_list,
  core_names,
  SIMPLIFY = FALSE
)

# Combine the data frames into one
combined_data <- do.call(rbind, data_list)

# Convert the data to long format
long_data <- combined_data %>%
  pivot_longer(
    cols = c(likes, views, comments, shares, collects),
    names_to = "metric",
    values_to = "value"
  )

# Ensure the date column is in the correct format
long_data$date <- as.Date(long_data$date)

# Function to remove outliers using IQR
remove_outliers <- function(data, metric) {
  q1 <- quantile(data$value, 0.25)
  q3 <- quantile(data$value, 0.75)
  iqr <- q3 - q1
  
  lower_bound <- q1 - 1.5 * iqr
  upper_bound <- q3 + 1.5 * iqr
  
  data %>% filter(value >= lower_bound, value <= upper_bound)
}

metrics <- c("likes", "views", "comments", "shares", "collects")

walk(metrics, function(metric) {
  metric_data <- long_data %>% 
    filter(metric == !!metric) %>% 
    group_by(core) %>% 
    do(remove_outliers(., !!metric))
  
  # Calculate the exact y-axis limits based on the data
  y_min <- min(metric_data$value)
  y_max <- max(metric_data$value)
  
  ggplot(metric_data, aes(x = date, y = value, color = core)) +
    geom_smooth(aes(color = core), 
                 method = "loess", 
                 method.args = list(span = 0.8), 
                 size = 2, 
                 se = FALSE) +
    geom_point(aes(x = date, y = value), 
               size = 0.5, 
               color = "grey", 
               alpha = 0.3) +
    labs(
      title = paste("Trend of", metric, "Over Time (Without Outliers)"),
      x = "Timeline",
      y = "Count",
      color = "Core"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
          legend.position = "bottom") +
    scale_color_brewer(palette = "Dark2") +
    theme(legend.title = element_blank()) +
    theme(plot.title = element_text(hjust = 0.5)) +
    scale_x_date(breaks = "2 month", date_labels = "%b %Y") +
    # Set y-axis limits to the exact data range
    scale_y_continuous(limits = c(y_min, y_max),
                        expand = expansion(c(0, -0.7)))  # Remove all padding
  
  ggsave(paste0("trend_", metric, "_metrics_without_outliers.png"), 
         width = 6, 
         height = 10, 
         dpi = 300)
})

```

```{r}

#do not use this. it is wrong how it filters out IQR
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)

# List of core files to process
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Read all CSV files into a list of data frames
data_list <- lapply(core_files, read.csv)

# Extract core names from file names
core_names <- gsub("_with_sentiment.csv", "", core_files)

# Add core name to each dataframe in the list
data_list <- mapply(
  function(df, core_name) {
    df$core <- core_name
    df
  },
  data_list,
  core_names,
  SIMPLIFY = FALSE
)

# Combine the data frames into one
combined_data <- do.call(rbind, data_list)

# Convert the data to long format
long_data <- combined_data %>%
  pivot_longer(
    cols = c(likes, views, comments, shares, collects),
    names_to = "metric",
    values_to = "value"
  )

# Ensure the date column is in the correct format
long_data$date <- as.Date(long_data$date)

# Function to remove outliers using IQR
remove_outliers <- function(data) {
  q1 <- quantile(data$value, 0.25)
  q3 <- quantile(data$value, 0.75)
  iqr <- q3 - q1
  
  lower_bound <- q1 - 1.5 * iqr
  upper_bound <- q3 + 1.5 * iqr
  
  data %>% filter(value >= lower_bound, value <= upper_bound)
}

# Create separate graphs for each metric with trendlines
metrics <- c("likes", "views", "comments", "shares", "collects")

walk(metrics, function(metric) {
  metric_data <- long_data %>% 
    filter(metric == !!metric) %>% 
    remove_outliers()
  
  # Calculate the exact y-axis limits based on the data
  y_min <- min(metric_data$value)
  y_max <- max(metric_data$value)
  
  ggplot(metric_data, aes(x = date, y = value, color = core)) +
    geom_smooth(aes(color = core), 
                 method = "loess", 
                 method.args = list(span = 0.8), 
                 size = 2, 
                 se = FALSE) +
    geom_point(aes(x = date, y = value), 
               size = 0.5, 
               color = "grey", 
               alpha = 0.3) +
    labs(
      title = paste("Trend of", metric, "Over Time (Without Outliers)"),
      x = "Timeline",
      y = "Count",
      color = "Core"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size= 12),
          legend.position = "bottom") +
    scale_color_brewer(palette = "Dark2") +
    theme(legend.title = element_blank()) +
    theme(plot.title = element_text(hjust = 0.5)) +
    scale_x_date(breaks = "2 month", date_labels = "%b %Y") + 
    # Set y-axis limits to the exact data range
    scale_y_continuous(limits = c(y_min, y_max),
                        expand = expansion(c(0, -0.6)))  # Remove all padding
  
  ggsave(paste0("trend_", metric, "_metrics_without_outliers.png"), 
         width = 6, 
         height = 10, 
         dpi = 300)
})
```




```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)

# List of core files to process
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Read all CSV files into a list of data frames
data_list <- lapply(core_files, read.csv)

# Extract core names from file names
core_names <- gsub("_with_sentiment.csv", "", core_files)

# Add core name to each dataframe in the list
data_list <- mapply(
  function(df, core_name) {
    df$core <- core_name
    df
  },
  data_list,
  core_names,
  SIMPLIFY = FALSE
)

# Combine the data frames into one
combined_data <- do.call(rbind, data_list)

# Convert the data to long format
long_data <- combined_data %>%
  pivot_longer(
    cols = c(likes, views, comments, shares, collects),
    names_to = "metric",
    values_to = "value"
  )

# Ensure the date column is in the correct format
long_data$date <- as.Date(long_data$date)

# Function to remove outliers using IQR
remove_outliers <- function(data, metric) {
  q1 <- quantile(data[[metric]], 0.25)
  q3 <- quantile(data[[metric]], 0.75)
  iqr <- q3 - q1
  
  lower_bound <- q1 - 1.5 * iqr
  upper_bound <- q3 + 1.5 * iqr
  
  data %>% filter(!!sym(metric) >= lower_bound, !!sym(metric) <= upper_bound)
}

# Calculate engagement rate
engagement_data <- long_data %>%
  pivot_wider(names_from = "metric", values_from = "value") %>%
  mutate(
    engagement_rate = ((likes + comments + shares + collects) / views) * 100
  ) %>%
  select(core, date, engagement_rate)

# Group by core and date, then calculate mean engagement rate
engagement_data <- engagement_data %>%
  group_by(core, date) %>%
  summarise(engagement_rate = mean(engagement_rate, na.rm = TRUE))

# Remove outliers for engagement rate
#engagement_data <- engagement_data %>%
#  group_by(core) %>%
#  mutate(
#    lower_bound = quantile(engagement_rate, 0.25) - 1.5 * IQR(engagement_rate),
#    upper_bound = quantile(engagement_rate, 0.75) + 1.5 * IQR(engagement_rate)
#  ) %>%
#  filter(engagement_rate >= lower_bound, engagement_rate <= upper_bound)

# Create the engagement rate trend plot
ggplot(engagement_data, aes(x = date, y = engagement_rate, color = core)) +
  geom_smooth(
    aes(color = core),
    method = "loess",
    method.args = list(span = 0.8),
    size = 2,
    se = FALSE
  ) +
  geom_point(
    aes(x = date, y = engagement_rate),
    size = 0.5,
    color = "grey",
    alpha = 0.3
  ) +
  labs(
    title = "Engagement Rate Trend Over Time",
    x = "Date",
    y = "Engagement Rate (%)",
    color = "Core"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
    legend.position = "bottom"
  ) +
  scale_color_brewer(palette = "Dark2") +
  theme(legend.title = element_blank()) +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_date(breaks = "2 month", date_labels = "%b %Y") +
  scale_y_continuous(expand = expansion(c(0, -0.6))) 

# Save the plot
ggsave("engagement_rate_trend.png", width = 6, height = 10, dpi = 300)
```

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)

# List of core files to process
core_files <- c(
  "Barbiecore_with_sentiment.csv",
  "Blokecore_with_sentiment.csv",
  "Coastalgirl_with_sentiment.csv",
  "Mermaidcore_with_sentiment.csv",
  "QuietLuxury_with_sentiment.csv",
  "Tomatogirl_with_sentiment.csv"
)

# Read all CSV files into a list of data frames
data_list <- lapply(core_files, read.csv)

# Extract core names from file names
core_names <- gsub("_with_sentiment.csv", "", core_files)

# Add core name to each dataframe in the list
data_list <- mapply(
  function(df, core_name) {
    df$core <- core_name
    df
  },
  data_list,
  core_names,
  SIMPLIFY = FALSE
)

# Combine the data frames into one
combined_data <- do.call(rbind, data_list)

# Convert the data to long format
long_data <- combined_data %>%
  pivot_longer(
    cols = c(sentiment),
    names_to = "metric",
    values_to = "value"
  )

# Ensure the date column is in the correct format
long_data$date <- as.Date(long_data$date)


metrics <- c("sentiment")

walk(metrics, function(metric) {
  metric_data <- long_data %>% 
    filter(metric == !!metric) %>% 
    group_by(core) 
  
  # Calculate the exact y-axis limits based on the data
  y_min <- min(metric_data$value)
  y_max <- max(metric_data$value)
  
  ggplot(metric_data, aes(x = date, y = value, color = core)) +
    geom_smooth(aes(color = core), 
                 method = "loess", 
                 method.args = list(span = 0.8), 
                 size = 2, 
                 se = FALSE) +
    geom_point(aes(x = date, y = value), 
               size = 0.5, 
               color = "grey", 
               alpha = 0.3) +
    labs(
      title = paste("Trend of", metric, "Over Time (Without Outliers)"),
      x = "Timeline",
      y = "Count",
      color = "Core"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
          legend.position = "bottom") +
    scale_color_brewer(palette = "Accent") +
    theme(legend.title = element_blank()) +
    theme(plot.title = element_text(hjust = 0.5)) +
    scale_x_date(breaks = "2 month", date_labels = "%b %Y") +
    # Set y-axis limits to the exact data range
    scale_y_continuous(limits = c(y_min, y_max),
                        expand = expansion(c(0, 0)))  # Remove all padding
  
  ggsave(paste0("trend_", metric, "_metrics_without_outliers.png"), 
         width = 6, 
         height = 10, 
         dpi = 300)
})
```

